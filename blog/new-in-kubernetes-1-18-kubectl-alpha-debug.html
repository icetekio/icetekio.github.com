<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="@Icetekio"/><meta property="og:locale" content="en_EN"/><meta property="og:site_name" content="Icetek | Hot technologies served cool"/><title>Icetek | New in Kubernetes 1.18 — kubectl alpha debug</title><meta name="robots" content="index,follow"/><meta name="description" content="Is it useful? What prolems can it help solve?"/><meta property="og:title" content="New in Kubernetes 1.18 — kubectl alpha debug"/><meta property="og:description" content="Is it useful? What prolems can it help solve?"/><meta property="og:url" content="https://icetek.io/blog/new-in-kubernetes-1-18-kubectl-alpha-debug"/><meta property="og:type" content="website"/><meta property="og:image" content="/blog-images/new-header-img.png"/><meta property="og:image:alt" content="New in Kubernetes 1.18 — kubectl alpha debug"/><meta name="next-head-count" content="15"/><meta charSet="utf-8"/><meta name="theme-color" content="#53E7FF"/><link rel="canonical" href="https://icetek.io/"/><link rel="apple-touch-icon" sizes="57x57" href="/images/favicon/apple-icon-57x57.png"/><link rel="apple-touch-icon" sizes="60x60" href="/images/favicon/apple-icon-60x60.png"/><link rel="apple-touch-icon" sizes="72x72" href="/images/favicon/apple-icon-72x72.png"/><link rel="apple-touch-icon" sizes="76x76" href="/images/favicon/apple-icon-76x76.png"/><link rel="apple-touch-icon" sizes="114x114" href="/images/favicon/apple-icon-114x114.png"/><link rel="apple-touch-icon" sizes="120x120" href="/images/favicon/apple-icon-120x120.png"/><link rel="apple-touch-icon" sizes="144x144" href="/images/favicon/apple-icon-144x144.png"/><link rel="apple-touch-icon" sizes="152x152" href="/images/favicon/apple-icon-152x152.png"/><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon/apple-icon-180x180.png"/><link rel="icon" type="image/png" sizes="192x192" href="/images/favicon/android-icon-192x192.png"/><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/images/favicon/favicon-96x96.png"/><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon/favicon-16x16.png"/><link rel="manifest" href="/manifest.json"/><link rel="preload" href="/fonts/iceGX.ttf" as="font" type="font/ttf" crossorigin="anonymous"/><link rel="preload" href="/fonts/Icetek_newGX.ttf" as="font" type="font/ttf" crossorigin="anonymous"/><link rel="preload" href="/fonts/3B1CDA_E_0.woff2" as="font" type="font/woff2" crossorigin="anonymous"/><link rel="preload" href="/fonts/3B1CDA_4_0.woff2" as="font" type="font/woff2" crossorigin="anonymous"/><link rel="preload" href="/fonts/3B1CDA_1_0.woff2" as="font" type="font/woff2" crossorigin="anonymous"/><link rel="preload" href="https://icetekio.github.io/_next/static/css/7874e3311df6741b.css" as="style"/><link rel="stylesheet" href="https://icetekio.github.io/_next/static/css/7874e3311df6741b.css" data-n-g=""/><link rel="preload" href="https://icetekio.github.io/_next/static/css/aa285a68ac3ec529.css" as="style"/><link rel="stylesheet" href="https://icetekio.github.io/_next/static/css/aa285a68ac3ec529.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="https://icetekio.github.io/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="https://icetekio.github.io/_next/static/chunks/webpack-7c1f8d751d6179a7.js" defer=""></script><script src="https://icetekio.github.io/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="https://icetekio.github.io/_next/static/chunks/main-d2a793b6dc23a82a.js" defer=""></script><script src="https://icetekio.github.io/_next/static/chunks/pages/_app-db38936be70ff848.js" defer=""></script><script src="https://icetekio.github.io/_next/static/chunks/839-ce0b23dc3526a602.js" defer=""></script><script src="https://icetekio.github.io/_next/static/chunks/pages/blog/%5Bslug%5D-0f775c16935d7180.js" defer=""></script><script src="https://icetekio.github.io/_next/static/BrQC3HtKOO_MNx4RlokCY/_buildManifest.js" defer=""></script><script src="https://icetekio.github.io/_next/static/BrQC3HtKOO_MNx4RlokCY/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="navbar navbar-expand-lg navbar-light bg-white fixed-top page-header"><a class="navbar-brand" href="/"><picture><img src="/images/logo.jpg" width="auto" height="100%" alt="Home"/></picture></a><button class="navbar-toggler collapsed" type="button" data-toggle="collapse" data-target="#navbarContent" aria-controls="navbarContent" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"><svg stroke="currentColor" fill="currentColor" stroke-width="0" version="1.1" viewBox="0 0 17 17" class="show-menu-icon nav-icon" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><g></g><path d="M16 3v2h-15v-2h15zM1 10h15v-2h-15v2zM1 15h15v-2h-15v2z"></path></svg><svg stroke="currentColor" fill="currentColor" stroke-width="0" version="1.1" viewBox="0 0 17 17" class="hide-menu-icon nav-icon" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><g></g><path d="M9.207 8.5l6.646 6.646-0.707 0.707-6.646-6.646-6.646 6.646-0.707-0.707 6.646-6.646-6.647-6.646 0.707-0.707 6.647 6.646 6.646-6.646 0.707 0.707-6.646 6.646z"></path></svg></span></button><div id="navbarContent" class="collapse navbar-collapse"><ul class="navbar-nav mr-auto"><li class="nav-item "><a class="nav-link" href="/">Home</a></li><li class="nav-item "><a class="nav-link" href="/products">Products</a></li><li class="nav-item "><a class="nav-link" href="/services">Services</a></li><li class="nav-item "><a class="nav-link" href="/contact">Contact</a></li><li class="nav-item active"><a class="nav-link" href="/blog">Blog</a></li></ul></div></header><div class="container"><div class="row"><div class="col-lg-10 m-auto"><div class="card-page"><div class="my-10"><div class="row"><div class="col-2"><picture><img class="card-img-top rounded-circle" src="/blog-images/dominik-andruszak.jpeg" alt="..."/></picture></div><div class="col align-self-center "><div class=" align-middle"><h6 class="small text-muted">Dominik Andruszak</h6><div class="small text-muted">31/3/2020</div></div></div></div></div><a href="/blog/new-in-kubernetes-1-18-kubectl-alpha-debug"><picture><img class="card-img-top" src="/blog-images/new-header-img.png" alt="..."/></picture></a><h1 class="card-title my-10">New in Kubernetes 1.18 — kubectl alpha debug</h1><div class="post-body my-10"><p>Kubernetes 1.18 has just landed and, as always, a couple of existing features got stabilized and a couple of new ones have been introduced. Let’s take a gander at one of the newest additions — <code>kubectl alpha debug</code>. This nifty <code>kubectl</code> feature gives you an additional tool for debugging pods when <code>kubectl exec</code> just doesn’t cut it. Most probably your application-hosting containers won’t have all the necessary debugging tools — they might not even have a shell. The <code>kubectl alpha debug</code> feature allows you to create a temporary container inside your pod — and that container can contain all the tools that you need.</p>
<h2 id="so-how-does-it-work">So.. how does it work?</h2>
<p><code>kubectl alpha debug</code> utilizes ephemeral containers — a kind of temporary container that can be added while the pod is running. Ephemeral containers are built for debugging purposes only — they have a stripped-down spec compared to base pod containers and they’re not really suitable for hosting applications. The feature is still in alpha and has to be enabled through a feature gate. You can read more about ephemeral containers in the Kubernetes <a href="https://kubernetes.io/docs/concepts/workloads/pods/ephemeral-containers/">https://kubernetes.io/docs/concepts/workloads/pods/ephemeral-containers/</a></p>
<h2 id="how-do-i-get-in">How do I get in?</h2>
<p>First, we have to make sure that we have version 1.18 for both the Kubernetes server and the client. Even though ephemeral containers were introduced in Kubernetes 1.16, using <code>kubectl</code> .18 with Kubernetes 1.16 didn&#39;t seem to work properly in my cluster.</p>
<pre><code class="language-yaml">$ kubectl version
Client Version: version.Info{Major:&quot;1&quot;, Minor:&quot;18&quot;, GitVersion:&quot;v1.18.0&quot;, GitCommit:&quot;9e991415386e4cf155a24b1da15becaa390438d8&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2020-03-25T14:58:59Z&quot;, GoVersion:&quot;go1.13.8&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;}
Server Version: version.Info{Major:&quot;1&quot;, Minor:&quot;18&quot;, GitVersion:&quot;v1.18.0&quot;, GitCommit:&quot;9e991415386e4cf155a24b1da15becaa390438d8&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2020-03-25T14:50:46Z&quot;, GoVersion:&quot;go1.13.8&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;}
</code></pre>
<p>We also have to enable ephemeral containers through a feature gate — in my examples, I’ll be using Minikube.</p>
<pre><code class="language-yaml">$ minikube config set feature-gates EphemeralContainers=true
❗  These changes will take effect upon a minikube delete and then a minikube start
</code></pre>
<p>Once the Minikube cluster is recreated, we’re pretty much good to go. Let’s create a simple pod and see what can we do.</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: simple
spec:
  containers:
    - image: alpine
      name: simple
      command:
        - &quot;/bin/sh&quot;
        - &quot;-c&quot;
        - &quot;sleep 5000&quot;
</code></pre>
<p>Save the file as simple.yaml and create the pod inside the cluster.</p>
<pre><code class="language-bash">$ kubectl apply -f simple.yaml
pod/simple created
</code></pre>
<p>Once the pod is up and running we can hop into it using the debug command. Please remember that the container image might have to download and the whole command might seem stuck for a while (there’s no visible indication of the download happening)</p>
<pre><code class="language-bash">$ kubectl alpha debug -it simple --image=ubuntu --target=simple --container=debug
If you don&#39;t see a command prompt, try pressing enter.
root@simple:/#
</code></pre>
<p>Let’s go through the parameters that we’ve passed to this command:</p>
<ul>
<li><code>-it</code> might look familiar and for a good reason - those two parameters are responsible for keeping the <code>stdin</code> open and allocating a TTY</li>
<li><code>--image</code> is the name of an image for the ephemeral container - it doesn&#39;t have to match the main container&#39;s image; in this example, we&#39;re using <code>ubuntu</code> even though the main container is running <code>alpine</code></li>
<li><code>--container</code> is the name of the ephemeral container itself</li>
<li><code>--target</code> lets the ephemeral container share a process namespace with a container inside the pod - we&#39;ll get back to that in a second</li>
</ul>
<p>Those params are also reflected in the updated spec of the <code>simple</code> pod in the cluster (the output is trimmed to just show the interesting part)</p>
<pre><code class="language-bash">$ kubectl get po simple -o yaml
(...)
ephemeralContainers:
  - image: ubuntu
    imagePullPolicy: IfNotPresent
    name: debug
    resources: {}
    stdin: true
    targetContainerName: simple
    terminationMessagePolicy: File
    tty: true
(...)
</code></pre>
<h2 id="whats-in-the-box">What&#39;s in the box?</h2>
<p>Since we’re attached to the debug container, let’s have a look around.</p>
<pre><code class="language-bash">root@simple:/# pwd
/
root@simple:/# ls
bin   dev  home  lib64  mnt  proc  run   srv  tmp  var
boot  etc  lib   media  opt  root  sbin  sys  usr
root@simple:/# whoami
root
root@simple:/# cat /etc/*-release
DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=18.04
DISTRIB_CODENAME=bionic
DISTRIB_DESCRIPTION=&quot;Ubuntu 18.04.4 LTS&quot;
NAME=&quot;Ubuntu&quot;
VERSION=&quot;18.04.4 LTS (Bionic Beaver)&quot;
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME=&quot;Ubuntu 18.04.4 LTS&quot;
VERSION_ID=&quot;18.04&quot;
HOME_URL=&quot;https://www.ubuntu.com/&quot;
SUPPORT_URL=&quot;https://help.ubuntu.com/&quot;
BUG_REPORT_URL=&quot;https://bugs.launchpad.net/ubuntu/&quot;
PRIVACY_POLICY_URL=&quot;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy&quot;
VERSION_CODENAME=bionic
UBUNTU_CODENAME=bionic
</code></pre>
<p>We’ve added a new <code>ubuntu</code> container to an existing pod (which was already running an <code>alpine</code> container) on the fly, pretty neat! So what can we do now? Well, for example, we can install and use tools like <code>nslookup</code> to debug and verify the pod networking and network policies.</p>
<pre><code class="language-bash">root@simple:/# nslookup google.com
Server:		10.96.0.10
Address:	10.96.0.10#53

Non-authoritative answer:
Name:	google.com
Address: 172.217.16.14
Name:	google.com
Address: 2a00:1450:401b:804::200e
</code></pre>
<p>What’s a bit more interesting — remember that <code>--target</code> parameter that we’ve passed to <code>kubectl alpha debug</code>? If we set its value to the name of our main container, it will share its (<a href="https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/">https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/</a>) with the ephemeral container. This means that our <code>debug</code> container sees all processes created by <code>simple</code>.</p>
<pre><code class="language-bash">root@simple:/# ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.0   1568     4 ?        Ss   08:47   0:00 sleep 5000
root         6  0.0  0.0  18504  3500 pts/0    Ss   08:48   0:00 /bin/bash
root       467  0.0  0.0  34400  2904 pts/0    R+   08:54   0:00 ps aux
root@simple:/# head -n 3 /proc/1/status
Name:	sleep
Umask:	0022
State:	S (sleeping)
</code></pre>
<p>Let’s try a different pod — a bit more complex this time around.</p>
<pre><code class="language-bash">apiVersion: v1
kind: Pod
metadata:
  name: complex
spec:
  containers:
  - image: alpine
    name: complex
    env:
    - name: ENV_FIRST
      value: first
    - name: ENV_SECOND
      value: second
    volumeMounts:
    - name: my-volume
      mountPath: /tmp/fromVolume
    command:
    - &quot;/bin/sh&quot;
    - &quot;-c&quot;
    - &quot;echo \&quot;Hello world\&quot; &gt; /tmp/echoed &amp;&amp; echo \&quot;Hello volume\&quot; &gt; /tmp/fromVolume/echoed &amp;&amp; sleep 5000&quot;
  volumes:
  - name: my-volume
    emptyDir: {}
</code></pre>
<p>Save it as <code>complex.yaml</code> — once it’s created, let’s jump right into the pod with a new debug container. As before, we can check out the main container processes.</p>
<pre><code class="language-bash">$ kubectl apply -f complex.yaml
pod/complex created
$ kubectl alpha debug -it complex --image=ubuntu --target=complex --container=debug
If you don&#39;t see a command prompt, try pressing enter.
root@complex:/# ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.0   1568     4 ?        Ss   09:06   0:00 sleep 5000
root         6  0.1  0.0  18504  3388 pts/0    Ss   09:06   0:00 /bin/bash
root        16  0.0  0.0  34400  2792 pts/0    R+   09:06   0:00 ps aux
</code></pre>
<p>We can peek at some of the resources used by that process as well, like files — both those created on the container’s ephemeral storage, as well as those created on a volume.</p>
<pre><code class="language-bash">root@complex:/# head /proc/1/root/tmp/echoed
Hello world
root@complex:/# head /proc/1/root/tmp/fromVolume/echoed
Hello volume
</code></pre>
<p>We can also check out the environment variables — the original output isn’t too human-friendly, I’ve reformatted it here for clarity.</p>
<pre><code class="language-bash">root@complex:/# head /proc/1/environ
KUBERNETES_PORT=tcp://10.96.0.1:443
KUBERNETES_SERVICE_PORT=443
HOSTNAME=complex
ENV_SECOND=second
SHLVL=1
HOME=/root
KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
KUBERNETES_PORT_443_TCP_PORT=443
KUBERNETES_PORT_443_TCP_PROTO=tcp
ENV_FIRST=first
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443
KUBERNETES_SERVICE_HOST=10.96.0.1
PWD=/
</code></pre>
<p>Finally, let’s see what happens when the main container inside the pod keeps crashing and restarting — let’s simulate this with a simple pod.</p>
<pre><code class="language-bash">apiVersion: v1
kind: Pod
metadata:
  name: crash
spec:
  containers:
  - image: alpine
    name: crash
    command:
    - &quot;/bin/sh&quot;
    - &quot;-c&quot;
    - &quot;sleep 3 &amp;&amp; whatisthis&quot;
</code></pre>
<p>Save this as crash.yaml and create it in the cluster — when we try to attach to the pod inside the container, the command seems to be stuck.</p>
<pre><code class="language-bash">$ kubectl apply -f crash.yaml
pod/crash created
$ kubectl alpha debug -it crash --image ubuntu --target=crash --container=debug
</code></pre>
<p>That’s actually true, a quick look into the pod description reveals that our <code>debug</code> container cannot be created, because the main container isn’t running. Does that mean that it’s not possible to debug the pod? Au contraire, we can still do it — just without the <code>--target</code> parameter. This still allows us to debug pod networking, for example.</p>
<pre><code class="language-bash">$ kubectl alpha debug -it crash --image ubuntu --container=debug-no-target
If you don&#39;t see a command prompt, try pressing enter.
root@crash:/# ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.2  0.0  18504  3300 pts/0    Ss   09:19   0:00 /bin/bash
root        10  0.0  0.0  34400  2900 pts/0    R+   09:19   0:00 ps aux
</code></pre>
<h2 id="final-thoughts">Final thoughts</h2>
<p>While still in its early stage, kubectl alpha debug shapes up to be a useful and potentially very powerful tool. There are a couple of use cases in which it might become really handy. Many of the containers running applications might not even have a shell, which renders kubectl exec unusable - the new debug feature allows for jumping into the pod without needing to change its manifest and recreating it. Even if a shell is available, the application containers most probably don&#39;t have all the tools necessary for debugging - and we might not want to install them manually inside a running container. With kubectl alpha debug we can create a kind of a &quot;tool belt&quot; image containing all the utilities that we use for debugging - and then simply create an ephemeral container in pods that have issues. Possibly it might even be used for attaching remote debuggers to applications running in pods.</p>
<p>All in all, kubectl alpha debug is a very interesting feature, looking forward to see how it evolves in future releases.</p>
</div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"data":{"author":"Dominik Andruszak","authorPhoto":"dominik-andruszak.jpeg","date":"2020-03-31T07:50:39Z","image":"new-header-img.png","slug":"new-in-kubernetes-1-18-kubectl-alpha-debug","summary":"Is it useful? What prolems can it help solve?","title":"New in Kubernetes 1.18 — kubectl alpha debug"},"slug":"new-in-kubernetes-1-18-kubectl-alpha-debug","content":"\nKubernetes 1.18 has just landed and, as always, a couple of existing features got stabilized and a couple of new ones have been introduced. Let’s take a gander at one of the newest additions — `kubectl alpha debug`. This nifty `kubectl` feature gives you an additional tool for debugging pods when `kubectl exec` just doesn’t cut it. Most probably your application-hosting containers won’t have all the necessary debugging tools — they might not even have a shell. The `kubectl alpha debug` feature allows you to create a temporary container inside your pod — and that container can contain all the tools that you need.\n\n## So.. how does it work?\n\n`kubectl alpha debug` utilizes ephemeral containers — a kind of temporary container that can be added while the pod is running. Ephemeral containers are built for debugging purposes only — they have a stripped-down spec compared to base pod containers and they’re not really suitable for hosting applications. The feature is still in alpha and has to be enabled through a feature gate. You can read more about ephemeral containers in the Kubernetes [https://kubernetes.io/docs/concepts/workloads/pods/ephemeral-containers/](https://kubernetes.io/docs/concepts/workloads/pods/ephemeral-containers/)\n\n## How do I get in?\n\nFirst, we have to make sure that we have version 1.18 for both the Kubernetes server and the client. Even though ephemeral containers were introduced in Kubernetes 1.16, using `kubectl` .18 with Kubernetes 1.16 didn't seem to work properly in my cluster.\n\n```yaml\n$ kubectl version\nClient Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.0\", GitCommit:\"9e991415386e4cf155a24b1da15becaa390438d8\", GitTreeState:\"clean\", BuildDate:\"2020-03-25T14:58:59Z\", GoVersion:\"go1.13.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.0\", GitCommit:\"9e991415386e4cf155a24b1da15becaa390438d8\", GitTreeState:\"clean\", BuildDate:\"2020-03-25T14:50:46Z\", GoVersion:\"go1.13.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n```\n\nWe also have to enable ephemeral containers through a feature gate — in my examples, I’ll be using Minikube.\n\n```yaml\n$ minikube config set feature-gates EphemeralContainers=true\n❗  These changes will take effect upon a minikube delete and then a minikube start\n```\n\nOnce the Minikube cluster is recreated, we’re pretty much good to go. Let’s create a simple pod and see what can we do.\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: simple\nspec:\n  containers:\n    - image: alpine\n      name: simple\n      command:\n        - \"/bin/sh\"\n        - \"-c\"\n        - \"sleep 5000\"\n```\n\nSave the file as simple.yaml and create the pod inside the cluster.\n\n```bash\n$ kubectl apply -f simple.yaml\npod/simple created\n```\n\nOnce the pod is up and running we can hop into it using the debug command. Please remember that the container image might have to download and the whole command might seem stuck for a while (there’s no visible indication of the download happening)\n\n```bash\n$ kubectl alpha debug -it simple --image=ubuntu --target=simple --container=debug\nIf you don't see a command prompt, try pressing enter.\nroot@simple:/#\n```\n\nLet’s go through the parameters that we’ve passed to this command:\n\n- `-it` might look familiar and for a good reason - those two parameters are responsible for keeping the `stdin` open and allocating a TTY\n- `--image` is the name of an image for the ephemeral container - it doesn't have to match the main container's image; in this example, we're using `ubuntu` even though the main container is running `alpine`\n- `--container` is the name of the ephemeral container itself\n- `--target` lets the ephemeral container share a process namespace with a container inside the pod - we'll get back to that in a second\n\nThose params are also reflected in the updated spec of the `simple` pod in the cluster (the output is trimmed to just show the interesting part)\n\n```bash\n$ kubectl get po simple -o yaml\n(...)\nephemeralContainers:\n  - image: ubuntu\n    imagePullPolicy: IfNotPresent\n    name: debug\n    resources: {}\n    stdin: true\n    targetContainerName: simple\n    terminationMessagePolicy: File\n    tty: true\n(...)\n```\n\n## What's in the box?\n\nSince we’re attached to the debug container, let’s have a look around.\n\n```bash\nroot@simple:/# pwd\n/\nroot@simple:/# ls\nbin   dev  home  lib64  mnt  proc  run   srv  tmp  var\nboot  etc  lib   media  opt  root  sbin  sys  usr\nroot@simple:/# whoami\nroot\nroot@simple:/# cat /etc/*-release\nDISTRIB_ID=Ubuntu\nDISTRIB_RELEASE=18.04\nDISTRIB_CODENAME=bionic\nDISTRIB_DESCRIPTION=\"Ubuntu 18.04.4 LTS\"\nNAME=\"Ubuntu\"\nVERSION=\"18.04.4 LTS (Bionic Beaver)\"\nID=ubuntu\nID_LIKE=debian\nPRETTY_NAME=\"Ubuntu 18.04.4 LTS\"\nVERSION_ID=\"18.04\"\nHOME_URL=\"https://www.ubuntu.com/\"\nSUPPORT_URL=\"https://help.ubuntu.com/\"\nBUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\nPRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\nVERSION_CODENAME=bionic\nUBUNTU_CODENAME=bionic\n```\n\nWe’ve added a new `ubuntu` container to an existing pod (which was already running an `alpine` container) on the fly, pretty neat! So what can we do now? Well, for example, we can install and use tools like `nslookup` to debug and verify the pod networking and network policies.\n\n```bash\nroot@simple:/# nslookup google.com\nServer:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nNon-authoritative answer:\nName:\tgoogle.com\nAddress: 172.217.16.14\nName:\tgoogle.com\nAddress: 2a00:1450:401b:804::200e\n```\n\nWhat’s a bit more interesting — remember that `--target` parameter that we’ve passed to `kubectl alpha debug`? If we set its value to the name of our main container, it will share its ([https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/](https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/)) with the ephemeral container. This means that our `debug` container sees all processes created by `simple`.\n\n```bash\nroot@simple:/# ps aux\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot         1  0.0  0.0   1568     4 ?        Ss   08:47   0:00 sleep 5000\nroot         6  0.0  0.0  18504  3500 pts/0    Ss   08:48   0:00 /bin/bash\nroot       467  0.0  0.0  34400  2904 pts/0    R+   08:54   0:00 ps aux\nroot@simple:/# head -n 3 /proc/1/status\nName:\tsleep\nUmask:\t0022\nState:\tS (sleeping)\n```\n\nLet’s try a different pod — a bit more complex this time around.\n\n```bash\napiVersion: v1\nkind: Pod\nmetadata:\n  name: complex\nspec:\n  containers:\n  - image: alpine\n    name: complex\n    env:\n    - name: ENV_FIRST\n      value: first\n    - name: ENV_SECOND\n      value: second\n    volumeMounts:\n    - name: my-volume\n      mountPath: /tmp/fromVolume\n    command:\n    - \"/bin/sh\"\n    - \"-c\"\n    - \"echo \\\"Hello world\\\" \u003e /tmp/echoed \u0026\u0026 echo \\\"Hello volume\\\" \u003e /tmp/fromVolume/echoed \u0026\u0026 sleep 5000\"\n  volumes:\n  - name: my-volume\n    emptyDir: {}\n```\n\nSave it as `complex.yaml` — once it’s created, let’s jump right into the pod with a new debug container. As before, we can check out the main container processes.\n\n```bash\n$ kubectl apply -f complex.yaml\npod/complex created\n$ kubectl alpha debug -it complex --image=ubuntu --target=complex --container=debug\nIf you don't see a command prompt, try pressing enter.\nroot@complex:/# ps aux\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot         1  0.0  0.0   1568     4 ?        Ss   09:06   0:00 sleep 5000\nroot         6  0.1  0.0  18504  3388 pts/0    Ss   09:06   0:00 /bin/bash\nroot        16  0.0  0.0  34400  2792 pts/0    R+   09:06   0:00 ps aux\n```\n\nWe can peek at some of the resources used by that process as well, like files — both those created on the container’s ephemeral storage, as well as those created on a volume.\n\n```bash\nroot@complex:/# head /proc/1/root/tmp/echoed\nHello world\nroot@complex:/# head /proc/1/root/tmp/fromVolume/echoed\nHello volume\n```\n\nWe can also check out the environment variables — the original output isn’t too human-friendly, I’ve reformatted it here for clarity.\n\n```bash\nroot@complex:/# head /proc/1/environ\nKUBERNETES_PORT=tcp://10.96.0.1:443\nKUBERNETES_SERVICE_PORT=443\nHOSTNAME=complex\nENV_SECOND=second\nSHLVL=1\nHOME=/root\nKUBERNETES_PORT_443_TCP_ADDR=10.96.0.1\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nENV_FIRST=first\nKUBERNETES_SERVICE_PORT_HTTPS=443\nKUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443\nKUBERNETES_SERVICE_HOST=10.96.0.1\nPWD=/\n```\n\nFinally, let’s see what happens when the main container inside the pod keeps crashing and restarting — let’s simulate this with a simple pod.\n\n```bash\napiVersion: v1\nkind: Pod\nmetadata:\n  name: crash\nspec:\n  containers:\n  - image: alpine\n    name: crash\n    command:\n    - \"/bin/sh\"\n    - \"-c\"\n    - \"sleep 3 \u0026\u0026 whatisthis\"\n```\n\nSave this as crash.yaml and create it in the cluster — when we try to attach to the pod inside the container, the command seems to be stuck.\n\n```bash\n$ kubectl apply -f crash.yaml\npod/crash created\n$ kubectl alpha debug -it crash --image ubuntu --target=crash --container=debug\n```\n\nThat’s actually true, a quick look into the pod description reveals that our `debug` container cannot be created, because the main container isn’t running. Does that mean that it’s not possible to debug the pod? Au contraire, we can still do it — just without the `--target` parameter. This still allows us to debug pod networking, for example.\n\n```bash\n$ kubectl alpha debug -it crash --image ubuntu --container=debug-no-target\nIf you don't see a command prompt, try pressing enter.\nroot@crash:/# ps aux\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot         1  0.2  0.0  18504  3300 pts/0    Ss   09:19   0:00 /bin/bash\nroot        10  0.0  0.0  34400  2900 pts/0    R+   09:19   0:00 ps aux\n```\n\n## Final thoughts\n\nWhile still in its early stage, kubectl alpha debug shapes up to be a useful and potentially very powerful tool. There are a couple of use cases in which it might become really handy. Many of the containers running applications might not even have a shell, which renders kubectl exec unusable - the new debug feature allows for jumping into the pod without needing to change its manifest and recreating it. Even if a shell is available, the application containers most probably don't have all the tools necessary for debugging - and we might not want to install them manually inside a running container. With kubectl alpha debug we can create a kind of a \"tool belt\" image containing all the utilities that we use for debugging - and then simply create an ephemeral container in pods that have issues. Possibly it might even be used for attaching remote debuggers to applications running in pods.\n\nAll in all, kubectl alpha debug is a very interesting feature, looking forward to see how it evolves in future releases.\n"},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"new-in-kubernetes-1-18-kubectl-alpha-debug"},"buildId":"BrQC3HtKOO_MNx4RlokCY","assetPrefix":"https://icetekio.github.io","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body><script defer="" src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script><script defer="" src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script defer="" src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script></html></body></html>