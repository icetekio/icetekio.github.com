<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="@Icetekio"/><meta property="og:locale" content="en_EN"/><meta property="og:site_name" content="Icetek | Hot technologies served cool"/><title>Icetek | Building a Kubernetes cluster on Raspberry Pi running Ubuntu server</title><meta name="robots" content="index,follow"/><meta name="description" content="In this article I will show how to set up a small Kubernetes cluster running on one or more Raspberry Pi 3/4 running Ubuntu server 18.04."/><meta property="og:title" content="Building a Kubernetes cluster on Raspberry Pi running Ubuntu server"/><meta property="og:description" content="In this article I will show how to set up a small Kubernetes cluster running on one or more Raspberry Pi 3/4 running Ubuntu server 18.04."/><meta property="og:url" content="https://icetek.io/blog/building-a-kubernetes-cluster-on-raspberry-pi-running-ubuntu-server"/><meta property="og:type" content="website"/><meta property="og:image" content="/blog-images/cluster-header-img.jpeg"/><meta property="og:image:alt" content="Building a Kubernetes cluster on Raspberry Pi running Ubuntu server"/><meta name="next-head-count" content="15"/><meta charSet="utf-8"/><meta name="theme-color" content="#53E7FF"/><link rel="canonical" href="https://icetek.io/"/><link rel="apple-touch-icon" sizes="57x57" href="/images/favicon/apple-icon-57x57.png"/><link rel="apple-touch-icon" sizes="60x60" href="/images/favicon/apple-icon-60x60.png"/><link rel="apple-touch-icon" sizes="72x72" href="/images/favicon/apple-icon-72x72.png"/><link rel="apple-touch-icon" sizes="76x76" href="/images/favicon/apple-icon-76x76.png"/><link rel="apple-touch-icon" sizes="114x114" href="/images/favicon/apple-icon-114x114.png"/><link rel="apple-touch-icon" sizes="120x120" href="/images/favicon/apple-icon-120x120.png"/><link rel="apple-touch-icon" sizes="144x144" href="/images/favicon/apple-icon-144x144.png"/><link rel="apple-touch-icon" sizes="152x152" href="/images/favicon/apple-icon-152x152.png"/><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon/apple-icon-180x180.png"/><link rel="icon" type="image/png" sizes="192x192" href="/images/favicon/android-icon-192x192.png"/><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/images/favicon/favicon-96x96.png"/><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon/favicon-16x16.png"/><link rel="manifest" href="/manifest.json"/><link rel="preload" href="/fonts/iceGX.ttf" as="font" type="font/ttf" crossorigin="anonymous"/><link rel="preload" href="/fonts/Icetek_newGX.ttf" as="font" type="font/ttf" crossorigin="anonymous"/><link rel="preload" href="/fonts/3B1CDA_E_0.woff2" as="font" type="font/woff2" crossorigin="anonymous"/><link rel="preload" href="/fonts/3B1CDA_4_0.woff2" as="font" type="font/woff2" crossorigin="anonymous"/><link rel="preload" href="/fonts/3B1CDA_1_0.woff2" as="font" type="font/woff2" crossorigin="anonymous"/><link rel="preload" href="https://icetekio.github.io/_next/static/css/7874e3311df6741b.css" as="style"/><link rel="stylesheet" href="https://icetekio.github.io/_next/static/css/7874e3311df6741b.css" data-n-g=""/><link rel="preload" href="https://icetekio.github.io/_next/static/css/aa285a68ac3ec529.css" as="style"/><link rel="stylesheet" href="https://icetekio.github.io/_next/static/css/aa285a68ac3ec529.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="https://icetekio.github.io/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="https://icetekio.github.io/_next/static/chunks/webpack-7c1f8d751d6179a7.js" defer=""></script><script src="https://icetekio.github.io/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="https://icetekio.github.io/_next/static/chunks/main-d2a793b6dc23a82a.js" defer=""></script><script src="https://icetekio.github.io/_next/static/chunks/pages/_app-db38936be70ff848.js" defer=""></script><script src="https://icetekio.github.io/_next/static/chunks/839-ce0b23dc3526a602.js" defer=""></script><script src="https://icetekio.github.io/_next/static/chunks/pages/blog/%5Bslug%5D-0f775c16935d7180.js" defer=""></script><script src="https://icetekio.github.io/_next/static/BrQC3HtKOO_MNx4RlokCY/_buildManifest.js" defer=""></script><script src="https://icetekio.github.io/_next/static/BrQC3HtKOO_MNx4RlokCY/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="navbar navbar-expand-lg navbar-light bg-white fixed-top page-header"><a class="navbar-brand" href="/"><picture><img src="/images/logo.jpg" width="auto" height="100%" alt="Home"/></picture></a><button class="navbar-toggler collapsed" type="button" data-toggle="collapse" data-target="#navbarContent" aria-controls="navbarContent" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"><svg stroke="currentColor" fill="currentColor" stroke-width="0" version="1.1" viewBox="0 0 17 17" class="show-menu-icon nav-icon" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><g></g><path d="M16 3v2h-15v-2h15zM1 10h15v-2h-15v2zM1 15h15v-2h-15v2z"></path></svg><svg stroke="currentColor" fill="currentColor" stroke-width="0" version="1.1" viewBox="0 0 17 17" class="hide-menu-icon nav-icon" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><g></g><path d="M9.207 8.5l6.646 6.646-0.707 0.707-6.646-6.646-6.646 6.646-0.707-0.707 6.646-6.646-6.647-6.646 0.707-0.707 6.647 6.646 6.646-6.646 0.707 0.707-6.646 6.646z"></path></svg></span></button><div id="navbarContent" class="collapse navbar-collapse"><ul class="navbar-nav mr-auto"><li class="nav-item "><a class="nav-link" href="/">Home</a></li><li class="nav-item "><a class="nav-link" href="/products">Products</a></li><li class="nav-item "><a class="nav-link" href="/services">Services</a></li><li class="nav-item "><a class="nav-link" href="/contact">Contact</a></li><li class="nav-item active"><a class="nav-link" href="/blog">Blog</a></li></ul></div></header><div class="container"><div class="row"><div class="col-lg-10 m-auto"><div class="card-page"><div class="my-10"><div class="row"><div class="col-2"><picture><img class="card-img-top rounded-circle" src="/blog-images/jakub-czaplinski.jpeg" alt="..."/></picture></div><div class="col align-self-center "><div class=" align-middle"><h6 class="small text-muted">Jakub Czapliński</h6><div class="small text-muted">9/4/2020</div></div></div></div></div><a href="/blog/building-a-kubernetes-cluster-on-raspberry-pi-running-ubuntu-server"><picture><img class="card-img-top" src="/blog-images/cluster-header-img.jpeg" alt="..."/></picture></a><h1 class="card-title my-10">Building a Kubernetes cluster on Raspberry Pi running Ubuntu server</h1><div class="post-body my-10"><p>In this article, I will show how to set up a small Kubernetes cluster running on one or more Raspberry Pi 3/4 running Ubuntu 18.04. I’ve chosen Ubuntu server as it comes with 64bit and 32bit versions and I need both types of nodes for my home cluster.</p>
<h2 id="why-should-anyone-bother">Why should anyone bother?</h2>
<p>As a low-energy consumption device, Raspberry Pi is a perfect candidate for a machine that will run 24/7. When learning or developing for Kubernetes sometimes a persistent environment is a time saver. K3s, on the other hand, is a smaller, easier-to-set-up flavor of Kubernetes that is fully compatible, though stripped down from unneeded features which are behind feature gates and by default disabled on most of the installations.</p>
<h2 id="who-is-it-for">Who is it for?</h2>
<p>The steps described in this tutorial do not require any practical experience with Kubernetes or its installation process. It is written so that someone starting their adventure with Kubernetes should be able to deploy it and start learning.</p>
<h2 id="what-do-we-need">What do we need</h2>
<p>To do everything shown in this tutorial you will need:</p>
<ul>
<li>1 or 2 Raspberry Pi (version 3 or 4)</li>
<li>1 or 2 micro SD cards - the faster the better</li>
<li>Power supplies for the Raspberry Pi</li>
<li>Software for writing disk images - more information can be found <a href="https://ubuntu.com/tutorials/tutorial-create-a-usb-stick-on-ubuntu#1-overview">https://ubuntu.com/tutorials/tutorial-create-a-usb-stick-on-ubuntu#1-overview</a></li>
<li>Ubuntu Raspberry Pi images found here <a href="https://ubuntu.com/download/raspberry-pi">https://ubuntu.com/download/raspberry-pi</a></li>
<li>K3sup - a great tool for simplifying installation of K3s <a href="https://github.com/alexellis/k3sup">https://github.com/alexellis/k3sup</a></li>
<li>30 minutes of your precious time</li>
<li>Coffee or other drink</li>
</ul>
<h2 id="plan">Plan</h2>
<p>What we will do (optional steps included):</p>
<ul>
<li>Prepare SD cards and SSH keys</li>
<li>Setup Ubuntu server 18.04 for K3s installation</li>
<li>Disable unnecessary services (optional)</li>
<li>Bootstrap K3s cluster</li>
<li>Join second node (optional)</li>
<li>Test K3s cluster</li>
<li>Dance the &quot;victory dance&quot; (optional)</li>
</ul>
<h2 id="preparing-for-the-installation">Preparing for the installation</h2>
<p>Before we begin the installation we need two things. First, we need to prepare SD cards with Ubuntu server 18.04. The images can be downloaded from <a href="https://ubuntu.com/download/raspberry-pi">here</a>. Instructions on how to prepare a bootable SD card from those images can be found <a href="https://ubuntu.com/tutorials/tutorial-create-a-usb-stick-on-ubuntu#1-overview">here</a>.</p>
<p>And second, we need to create SSH keys for k3sup, so we’ll be able to install K3s on a Raspberry Pi node. If you have your own SSH keys, you can skip this step. To create SSH keys run the following:</p>
<pre><code class="language-bash">ssh-keygen -t rsa -b 4096 -f ~/.ssh/rpi -P &quot;&quot;
</code></pre>
<p>and add it to ssh key</p>
<pre><code class="language-bash">ssh-add ~/.ssh/rpi
</code></pre>
<h2 id="installation">Installation</h2>
<p>After booting up your Raspberry Pi with the fresh Ubuntu installation, you have to check its IP address. To do that, log into your router and check the DHCP settings for a new lease for a hostname “ubuntu”. You can also do it the old-fashioned way by connecting the keyboard and monitor to your Raspberry Pi and logging into the machine. Both the username and login <strong>ubuntu -</strong>. Logged in, immediately change your password, and log in once again. Once you’re there run</p>
<pre><code class="language-bash">ip addr show eth0
</code></pre>
<p>And you should see something like this:</p>
<pre><code class="language-bash">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether dc:a6:32:76:1b:91 brd ff:ff:ff:ff:ff:ff
    inet 192.168.0.238/24 brd 192.168.0.255 scope global dynamic eth0
       valid_lft 329sec preferred_lft 329sec
    inet6 fe80::dea6:32ff:fe76:1b91/64 scope link
       valid_lft forever preferred_lft forev
</code></pre>
<p>OK, from now we can remotely log into the machine and the keyboard and monitor won’t be necessary.</p>
<p>Let’s log into the machine by running</p>
<pre><code class="language-bash">ssh ubuntu@192.168.0.238
</code></pre>
<p>If you did not log in before you would have to change your password.</p>
<p>Let’s log out and copy the SSH keys, so we won’t have to use the password every time we log in. It will also let <strong>k3sup</strong> deploy the Kubernetes cluster. To copy the SSH keys to the machine run the following</p>
<pre><code class="language-bash">ssh-copy-id -i .ssh/rpi ubuntu@192.168.0.238
</code></pre>
<p>You should be prompted for the password and after successful login, you should see something like this</p>
<pre><code class="language-bash">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;.ssh/rpi.pub&quot;
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
ubuntu@192.168.0.238&#39;s password:

Number of key(s) added: 1

Now try logging into the machine, with:   &quot;ssh &#39;ubuntu@192.168.0.238&#39;&quot;
and check to make sure that only the key(s) you wanted were added.
</code></pre>
<p>Now we can SSH into the Raspberry Pi and finish the system installation.</p>
<p>Let’s check how much resources are used by the system</p>
<pre><code class="language-bash">ubuntu@ubuntu:~$ free -m
              total        used        free      shared  buff/cache   available
Mem:           3791         183        2369           6        1238        3552
Swap:             0           0           0
ubuntu@ubuntu:~$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 2426232  77056 1191676    0    0    81   261  182  192 10  5 84  2  0
 0  0      0 2426232  77056 1191704    0    0     0     0   53   48  0  0 100  0  0
 0  0      0 2426232  77056 1191704    0    0     0     0   46   44  0  0 100  0  0
 0  0      0 2426232  77056 1191704    0    0     0     0   57   59  0  0 100  0  0
 0  0      0 2426232  77064 1191696    0    0     0    28   62   70  0  0 100  0  0
 0  0      0 2426264  77064 1191712    0    0     0     0   53   57  0  0 100  0  0
 0  0      0 2426232  77064 1191712    0    0     0     0   64   75  0  0 100  0  0
 0  0      0 2426232  77064 1191712    0    0     0     0   49   47  0  0 100  0  0
 0  0      0 2426232  77064 1191712    0    0     0     0   48   47  0  0 100  0  0
 0  0      0 2426232  77064 1191712    0    0     0    20   48   49  0  0 100  0  0
 0  0      0 2426232  77064 1191712    0    0     0     0   71   73  0  0 100  0  0
 0  0      0 2426232  77064 1191712    0    0     0     0   48   48  0  0 100  0  0
</code></pre>
<p>As we can see, the base resource utilization is very low and the Raspberry Pi has quite a bit to offer :)</p>
<p>Let’s do a quick system update and then make one necessary change so the Kubernetes will work on this machine.</p>
<pre><code class="language-bash">sudo apt-get update
sudo apt-get upgrade -y
</code></pre>
<p>Now let’s edit the boot options <strong>/boot/firmware/nobtcmd.txt</strong> and add <strong>cgroup_memory=1 cgroup_enable=memory</strong> to the end of the line so that file will look like this</p>
<pre><code class="language-bash">ubuntu@ubuntu:~$ cat /boot/firmware/nobtcmd.txt
net.ifnames=0 dwc_otg.lpm_enable=0 console=ttyAMA0,115200 console=tty1 root=LABEL=writable rootfstype=ext4 elevator=deadline rootwait fixrtc cgroup_memory=1 cgroup_enable=memory
</code></pre>
<p>If you skip this part K3s will fail after bootstrapping the cluster and you will be able to find something along those lines in the logs:</p>
<pre><code class="language-bash">Apr  4 20:22:27 rpi-master k3s[2204]: time=&quot;2020-04-04T20:22:27.635180523Z&quot; level=error msg=&quot;Failed to find memory cgroup, you may need to add \&quot;cgroup_memory=1 cgroup_enable=memory\&quot; to your linux cmdline (/boot/cmdline.txt on a Raspberry Pi)&quot;
</code></pre>
<p>however, on ubuntu it’s actually the <strong>nobtmcd.txt</strong> file.</p>
<p>Now, we need to ensure that the Raspberry Pi has a static IP. This is important for both the master and all the additional nodes. If you have access and know how, you can just set the IP on your router to be static, so that after every reboot the machine will always get the same IP. Alternatively, we can set up our Ubuntu to have a static IP. To do this, we need to edit the file <strong>/etc/netplan/50-cloud-init.yaml</strong> to look like this:</p>
<pre><code class="language-bash">network:
  version: 2
  renderer: networkd
  ethernets:
    eth0:
     dhcp4: no
     addresses: [192.168.0.120/24]
     gateway4: 192.168.0.1
     nameservers:
       addresses: [8.8.8.8,8.8.4.4]
</code></pre>
<p>More information about this topic can be found here <a href="https://linuxconfig.org/how-to-configure-static-ip-address-on-ubuntu-18-04-bionic-beaver-linux">https://linuxconfig.org/how-to-configure-static-ip-address-on-ubuntu-18-04-bionic-beaver-linux</a></p>
<p>The last thing to do is to set up a unique and friendly hostname, as “ubuntu” will be too generic — especially when we will have more than 1 node. To do so, edit the <strong>/etc/hostname</strong> and set the name to your liking. I chose <strong>rpi-master</strong> for my master node.</p>
<p>This is it for the installation, you can repeat this process on a second node. I’ve set up my second Raspberry Pi with the IP <strong>192.168.0.121</strong> and hostname <strong>rpi-worker-1</strong></p>
<h2 id="optimizations-optional">Optimizations (optional)</h2>
<p>As I dislike having anything unnecessary running in my system (not to mention running many tests and benchmarks on my cluster), I rather not have time-based actions or system updates done automatically. Because of that, I prefer to remove almost every service from the system.</p>
<p>To disable all the services that are not needed for running k3s run the following</p>
<pre><code class="language-bash"># no WIFI for the server
sudo systemctl disable wpa_supplicant.service
# no time based tasks executed
sudo systemctl disable atd.service
sudo systemctl disable cron
# no restart of services and auto updates - I prefer to run updates myself
sudo systemctl disable unattended-upgrades.service
</code></pre>
<p>reboot and....</p>
<pre><code class="language-bash">ubuntu@rpi-master:~$ free -m
              total        used        free      shared  buff/cache   available
Mem:           3791         169        3423           6         198        3566
Swap:             0           0           0
</code></pre>
<p>OK, so we’ve gained 14 MB, and we can be sure that nothing will suddenly run in the background while running tests. As I love to min/max things, I’m happy with the result!</p>
<h2 id="bootstrapping-the-cluster">Bootstrapping the cluster</h2>
<p>To bootstrap the K3s cluster run the following command</p>
<pre><code class="language-bash">k3sup install --user ubuntu --sudo --ip 192.168.0.120 --ssh-key ~/.ssh/rpi
</code></pre>
<p>and validate by running</p>
<pre><code class="language-bash">export KUBECONFIG=/home/upgrade/kubeconfig
</code></pre>
<p>Wait 1–5 minutes, depending on your network bandwidth and you should be able to run the same commands and have similar output</p>
<pre><code class="language-bash">upgrade@ZeroOne ~ $ kubectl get pod -A
NAMESPACE     NAME                                      READY   STATUS      RESTARTS   AGE
kube-system   local-path-provisioner-58fb86bdfd-hmcbr   1/1     Running     0          104s
kube-system   metrics-server-6d684c7b5-dl27c            1/1     Running     0          104s
kube-system   coredns-d798c9dd-zhht7                    1/1     Running     0          104s
kube-system   helm-install-traefik-s2hzn                0/1     Completed   2          104s
kube-system   svclb-traefik-4cwg9                       2/2     Running     0          29s
kube-system   traefik-6787cddb4b-kcj9j                  1/1     Running     0          30s
upgrade@ZeroOne ~ $ kubectl  cluster-info
Kubernetes master is running at https://192.168.0.120:6443
CoreDNS is running at https://192.168.0.120:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
Metrics-server is running at https://192.168.0.120:6443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy

To further debug and diagnose cluster problems, use &#39;kubectl cluster-info dump&#39;.
</code></pre>
<p>And the cluster is up and running!</p>
<p>If this is your only cluster, copy the config file to <strong>~/.kube/config</strong> for convenience. You won’t have to export the environment variable <strong>KUBECONFIG</strong> to access this cluster.</p>
<p>As we can see the load on our master node jumped up a bit</p>
<pre><code class="language-bash">ubuntu@rpi-master:~$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 2218940  29752 873468    0    0    82   614  978 1593 10  9 76  6  0
 0  0      0 2218688  29752 873496    0    0     0     0 2855 5331  2  3 95  0  0
 0  0      0 2218688  29760 873496    0    0     0    32 2463 4605  1  2 97  0  0
 2  0      0 2217132  29760 873496    0    0     0     0 5417 9919  5 12 83  0  0
 0  0      0 2217964  29760 873496    0    0     0     0 3459 5780  1 20 78  0  0
 0  0      0 2217664  29760 873496    0    0     0     0 3194 5897  3  4 94  0  0
 0  0      0 2218924  29760 873496    0    0     0     0 4327 7566  4 13 83  0  0
 0  0      0 2218672  29768 873496    0    0     0    24 3040 5547  2  3 95  0  0
 1  0      0 2218672  29768 873496    0    0     0     4 2758 5124  2  3 95  0  0
 4  0      0 2218672  29768 873496    0    0     0     0 3057 5681  2  3 95  0  0
 0  0      0 2218704  29768 873496    0    0     0     0 3480 6466  3  3 94  0  0
 0  0      0 2218704  29768 873496    0    0     0     0 3130 5789  2  2 95  0  0
</code></pre>
<p>But there is still plenty of resources for our apps to use.</p>
<p>We can also verify if Traefik and the service load balancer (which emulates cloud load balancers) are working, by trying to connect to the IP of the cluster master through the browser or by running the following</p>
<pre><code class="language-bash">upgrade@ZeroOne ~ $ curl http://192.168.0.120
404 page not found
</code></pre>
<p>We got a response, so that means the ingress is also working correctly. We just don’t have anything deployed yet, so Traefik does not serve anything.</p>
<h2 id="join-the-node">Join the node</h2>
<pre><code class="language-bash">k3sup join --user ubuntu --sudo  --ssh-key ~/.ssh/upgnet/rpi  --server-ip 192.168.0.120  --ip 192.168.0.121
</code></pre>
<p>wait a couple of seconds and ... TADAM!</p>
<pre><code class="language-bash">upgrade@ZeroOne ~ $ kubectl get node
NAME           STATUS   ROLES    AGE   VERSION
rpi-master     Ready    master   21m   v1.17.2+k3s1
rpi-worker-1   Ready    &lt;none&gt;   17s   v1.17.2+k3s1
upgrade@ZeroOne ~ $ kubectl top node
NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
rpi-master     367m         9%     712Mi           18%
rpi-worker-1   51m          1%     221Mi           5%
</code></pre>
<p>If you SSH into the node and run</p>
<pre><code class="language-bash">ubuntu@rpi-worker-1:~$ free -m
              total        used        free      shared  buff/cache   available
Mem:           3822         227        3222          10         372        3546
Swap:             0           0           0
ubuntu@rpi-worker-1:~$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 2  0      0 3299888  19420 361952    0    0   193   256  289  390  4  5 90  2  0
 0  0      0 3299660  19420 361980    0    0     0     0  614 1029  1  1 98  0  0
 1  0      0 3299660  19420 361980    0    0     0    16  578  994  1  0 99  0  0
 1  0      0 3299628  19420 361980    0    0     0     0  544  951  0  1 99  0  0
 1  0      0 3299628  19420 361980    0    0     0     0  346  582  0  0 100  0  0
 0  0      0 3299504  19428 361980    0    0     0    12  597 1013  1  1 99  0  0
 0  0      0 3299472  19428 361996    0    0     0     0  530  893  1  0 99  0  0
 0  0      0 3299472  19428 361996    0    0     0     0  986 1721  1  1 98  0  0
 1  0      0 3299220  19428 361996    0    0     0     0 1138 1940  1  2 97  0  0
 1  0      0 3299220  19428 361996    0    0     0     0  718 1249  0  1 99  0  0
 1  0      0 3298968  19428 361996    0    0     0     0  507  844  0  1 99  0  0
</code></pre>
<p>you will see that the performance hit is mostly on the master. The worker node still has almost all resources available — which is also reflected by the output of the <strong>kubectl top node</strong> command.</p>
<h2 id="it-wasnt-that-bad-was-it">It wasn’t that bad, was it?</h2>
<p>Cool! So now we have our Kubernetes cluster with Traefik as Ingress controller, metrics service and a local storage provisioner. And the whole preparation took way longer than the cluster setup itself. Now it’s time to explore Kubernetes with all its glory!</p>
<h2 id="and-for-all-you-ui-lovers">And for all you UI lovers</h2>
<p>If you like UI, especially the console ones, I strongly recommend using K9s that you can find <a href="https://github.com/derailed/k9s">here</a></p>
<p>Here is the state of the cluster shown in K9s</p>
<p><img src="/blog-images/list-of-pods-in-the-K9s-UI.png" alt="list-of-pods-in-the-K9s-UI"></p>
<p><img src="/blog-images/list-of-nodes-in-the-K9s-UI.png" alt="list-of-nodes-in-the-K9s-UI"></p>
<h2 id="where-do-we-go-from-here">Where do we go from here?</h2>
<p>So now you have a complete running Kubernetes cluster, with one or two nodes. Traefik ingress controller is set up so you can deploy any application and use its built-in option to obtain SSL certificates to run it securely even from home. The metrics service is there, so initial monitoring of your applications is enabled and you can learn a lot about their behavior in the cluster. You can also start learning Kubernetes and training for the CKAD and CKA certification if you fancy, as you can practice almost everything apart from setting up a cluster on this cluster ;) As for me, I’m planning to deploy <a href="https://iceci.io/">IceCI</a> to the cluster and start building more applications for the ARM architecture.</p>
<p>Readout:</p>
<p>Traefik: <a href="https://docs.traefik.io/">https://docs.traefik.io/</a></p>
<p>K3s: <a href="https://k3s.io/">https://k3s.io/</a></p>
<p>K3sup: <a href="https://github.com/alexellis/k3sup">https://github.com/alexellis/k3sup</a></p>
<p>K9s: <a href="https://github.com/derailed/k9s">https://github.com/derailed/k9s</a></p>
<p>Kubernetes documentation: <a href="https://kubernetes.io/docs/setup/">https://kubernetes.io/docs/setup/</a></p>
</div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"data":{"author":"Jakub Czapliński","authorPhoto":"jakub-czaplinski.jpeg","date":"2020-04-09T07:50:39Z","image":"cluster-header-img.jpeg","slug":"building-a-kubernetes-cluster-on-raspberry-pi-running-ubuntu-server","summary":"In this article I will show how to set up a small Kubernetes cluster running on one or more Raspberry Pi 3/4 running Ubuntu server 18.04.","title":"Building a Kubernetes cluster on Raspberry Pi running Ubuntu server"},"slug":"building-a-kubernetes-cluster-on-raspberry-pi-running-ubuntu-server","content":"\nIn this article, I will show how to set up a small Kubernetes cluster running on one or more Raspberry Pi 3/4 running Ubuntu 18.04. I’ve chosen Ubuntu server as it comes with 64bit and 32bit versions and I need both types of nodes for my home cluster.\n\n## Why should anyone bother?\n\nAs a low-energy consumption device, Raspberry Pi is a perfect candidate for a machine that will run 24/7. When learning or developing for Kubernetes sometimes a persistent environment is a time saver. K3s, on the other hand, is a smaller, easier-to-set-up flavor of Kubernetes that is fully compatible, though stripped down from unneeded features which are behind feature gates and by default disabled on most of the installations.\n\n## Who is it for?\n\nThe steps described in this tutorial do not require any practical experience with Kubernetes or its installation process. It is written so that someone starting their adventure with Kubernetes should be able to deploy it and start learning.\n\n## What do we need\n\nTo do everything shown in this tutorial you will need:\n\n- 1 or 2 Raspberry Pi (version 3 or 4)\n- 1 or 2 micro SD cards - the faster the better\n- Power supplies for the Raspberry Pi\n- Software for writing disk images - more information can be found [https://ubuntu.com/tutorials/tutorial-create-a-usb-stick-on-ubuntu#1-overview](https://ubuntu.com/tutorials/tutorial-create-a-usb-stick-on-ubuntu#1-overview)\n- Ubuntu Raspberry Pi images found here [https://ubuntu.com/download/raspberry-pi](https://ubuntu.com/download/raspberry-pi)\n- K3sup - a great tool for simplifying installation of K3s [https://github.com/alexellis/k3sup](https://github.com/alexellis/k3sup)\n- 30 minutes of your precious time\n- Coffee or other drink\n\n## Plan\n\nWhat we will do (optional steps included):\n\n- Prepare SD cards and SSH keys\n- Setup Ubuntu server 18.04 for K3s installation\n- Disable unnecessary services (optional)\n- Bootstrap K3s cluster\n- Join second node (optional)\n- Test K3s cluster\n- Dance the \"victory dance\" (optional)\n\n## Preparing for the installation\n\nBefore we begin the installation we need two things. First, we need to prepare SD cards with Ubuntu server 18.04. The images can be downloaded from [here](https://ubuntu.com/download/raspberry-pi). Instructions on how to prepare a bootable SD card from those images can be found [here](https://ubuntu.com/tutorials/tutorial-create-a-usb-stick-on-ubuntu#1-overview).\n\nAnd second, we need to create SSH keys for k3sup, so we’ll be able to install K3s on a Raspberry Pi node. If you have your own SSH keys, you can skip this step. To create SSH keys run the following:\n\n```bash\nssh-keygen -t rsa -b 4096 -f ~/.ssh/rpi -P \"\"\n```\n\nand add it to ssh key\n\n```bash\nssh-add ~/.ssh/rpi\n```\n\n## Installation\n\nAfter booting up your Raspberry Pi with the fresh Ubuntu installation, you have to check its IP address. To do that, log into your router and check the DHCP settings for a new lease for a hostname “ubuntu”. You can also do it the old-fashioned way by connecting the keyboard and monitor to your Raspberry Pi and logging into the machine. Both the username and login **ubuntu -**. Logged in, immediately change your password, and log in once again. Once you’re there run\n\n```bash\nip addr show eth0\n```\n\nAnd you should see something like this:\n\n```bash\n2: eth0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc mq state UP group default qlen 1000\n    link/ether dc:a6:32:76:1b:91 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.0.238/24 brd 192.168.0.255 scope global dynamic eth0\n       valid_lft 329sec preferred_lft 329sec\n    inet6 fe80::dea6:32ff:fe76:1b91/64 scope link\n       valid_lft forever preferred_lft forev\n```\n\nOK, from now we can remotely log into the machine and the keyboard and monitor won’t be necessary.\n\nLet’s log into the machine by running\n\n```bash\nssh ubuntu@192.168.0.238\n```\n\nIf you did not log in before you would have to change your password.\n\nLet’s log out and copy the SSH keys, so we won’t have to use the password every time we log in. It will also let **k3sup** deploy the Kubernetes cluster. To copy the SSH keys to the machine run the following\n\n```bash\nssh-copy-id -i .ssh/rpi ubuntu@192.168.0.238\n```\n\nYou should be prompted for the password and after successful login, you should see something like this\n\n```bash\n/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \".ssh/rpi.pub\"\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\nubuntu@192.168.0.238's password:\n\nNumber of key(s) added: 1\n\nNow try logging into the machine, with:   \"ssh 'ubuntu@192.168.0.238'\"\nand check to make sure that only the key(s) you wanted were added.\n```\n\nNow we can SSH into the Raspberry Pi and finish the system installation.\n\nLet’s check how much resources are used by the system\n\n```bash\nubuntu@ubuntu:~$ free -m\n              total        used        free      shared  buff/cache   available\nMem:           3791         183        2369           6        1238        3552\nSwap:             0           0           0\nubuntu@ubuntu:~$ vmstat 1\nprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n 0  0      0 2426232  77056 1191676    0    0    81   261  182  192 10  5 84  2  0\n 0  0      0 2426232  77056 1191704    0    0     0     0   53   48  0  0 100  0  0\n 0  0      0 2426232  77056 1191704    0    0     0     0   46   44  0  0 100  0  0\n 0  0      0 2426232  77056 1191704    0    0     0     0   57   59  0  0 100  0  0\n 0  0      0 2426232  77064 1191696    0    0     0    28   62   70  0  0 100  0  0\n 0  0      0 2426264  77064 1191712    0    0     0     0   53   57  0  0 100  0  0\n 0  0      0 2426232  77064 1191712    0    0     0     0   64   75  0  0 100  0  0\n 0  0      0 2426232  77064 1191712    0    0     0     0   49   47  0  0 100  0  0\n 0  0      0 2426232  77064 1191712    0    0     0     0   48   47  0  0 100  0  0\n 0  0      0 2426232  77064 1191712    0    0     0    20   48   49  0  0 100  0  0\n 0  0      0 2426232  77064 1191712    0    0     0     0   71   73  0  0 100  0  0\n 0  0      0 2426232  77064 1191712    0    0     0     0   48   48  0  0 100  0  0\n```\n\nAs we can see, the base resource utilization is very low and the Raspberry Pi has quite a bit to offer :)\n\nLet’s do a quick system update and then make one necessary change so the Kubernetes will work on this machine.\n\n```bash\nsudo apt-get update\nsudo apt-get upgrade -y\n```\n\nNow let’s edit the boot options **/boot/firmware/nobtcmd.txt** and add **cgroup_memory=1 cgroup_enable=memory** to the end of the line so that file will look like this\n\n```bash\nubuntu@ubuntu:~$ cat /boot/firmware/nobtcmd.txt\nnet.ifnames=0 dwc_otg.lpm_enable=0 console=ttyAMA0,115200 console=tty1 root=LABEL=writable rootfstype=ext4 elevator=deadline rootwait fixrtc cgroup_memory=1 cgroup_enable=memory\n```\n\nIf you skip this part K3s will fail after bootstrapping the cluster and you will be able to find something along those lines in the logs:\n\n```bash\nApr  4 20:22:27 rpi-master k3s[2204]: time=\"2020-04-04T20:22:27.635180523Z\" level=error msg=\"Failed to find memory cgroup, you may need to add \\\"cgroup_memory=1 cgroup_enable=memory\\\" to your linux cmdline (/boot/cmdline.txt on a Raspberry Pi)\"\n```\n\nhowever, on ubuntu it’s actually the **nobtmcd.txt** file.\n\nNow, we need to ensure that the Raspberry Pi has a static IP. This is important for both the master and all the additional nodes. If you have access and know how, you can just set the IP on your router to be static, so that after every reboot the machine will always get the same IP. Alternatively, we can set up our Ubuntu to have a static IP. To do this, we need to edit the file **/etc/netplan/50-cloud-init.yaml** to look like this:\n\n```bash\nnetwork:\n  version: 2\n  renderer: networkd\n  ethernets:\n    eth0:\n     dhcp4: no\n     addresses: [192.168.0.120/24]\n     gateway4: 192.168.0.1\n     nameservers:\n       addresses: [8.8.8.8,8.8.4.4]\n```\n\nMore information about this topic can be found here [https://linuxconfig.org/how-to-configure-static-ip-address-on-ubuntu-18-04-bionic-beaver-linux](https://linuxconfig.org/how-to-configure-static-ip-address-on-ubuntu-18-04-bionic-beaver-linux)\n\nThe last thing to do is to set up a unique and friendly hostname, as “ubuntu” will be too generic — especially when we will have more than 1 node. To do so, edit the **/etc/hostname** and set the name to your liking. I chose **rpi-master** for my master node.\n\nThis is it for the installation, you can repeat this process on a second node. I’ve set up my second Raspberry Pi with the IP **192.168.0.121** and hostname **rpi-worker-1**\n\n## Optimizations (optional)\n\nAs I dislike having anything unnecessary running in my system (not to mention running many tests and benchmarks on my cluster), I rather not have time-based actions or system updates done automatically. Because of that, I prefer to remove almost every service from the system.\n\nTo disable all the services that are not needed for running k3s run the following\n\n```bash\n# no WIFI for the server\nsudo systemctl disable wpa_supplicant.service\n# no time based tasks executed\nsudo systemctl disable atd.service\nsudo systemctl disable cron\n# no restart of services and auto updates - I prefer to run updates myself\nsudo systemctl disable unattended-upgrades.service\n```\n\nreboot and....\n\n```bash\nubuntu@rpi-master:~$ free -m\n              total        used        free      shared  buff/cache   available\nMem:           3791         169        3423           6         198        3566\nSwap:             0           0           0\n```\n\nOK, so we’ve gained 14 MB, and we can be sure that nothing will suddenly run in the background while running tests. As I love to min/max things, I’m happy with the result!\n\n## Bootstrapping the cluster\n\nTo bootstrap the K3s cluster run the following command\n\n```bash\nk3sup install --user ubuntu --sudo --ip 192.168.0.120 --ssh-key ~/.ssh/rpi\n```\n\nand validate by running\n\n```bash\nexport KUBECONFIG=/home/upgrade/kubeconfig\n```\n\nWait 1–5 minutes, depending on your network bandwidth and you should be able to run the same commands and have similar output\n\n```bash\nupgrade@ZeroOne ~ $ kubectl get pod -A\nNAMESPACE     NAME                                      READY   STATUS      RESTARTS   AGE\nkube-system   local-path-provisioner-58fb86bdfd-hmcbr   1/1     Running     0          104s\nkube-system   metrics-server-6d684c7b5-dl27c            1/1     Running     0          104s\nkube-system   coredns-d798c9dd-zhht7                    1/1     Running     0          104s\nkube-system   helm-install-traefik-s2hzn                0/1     Completed   2          104s\nkube-system   svclb-traefik-4cwg9                       2/2     Running     0          29s\nkube-system   traefik-6787cddb4b-kcj9j                  1/1     Running     0          30s\nupgrade@ZeroOne ~ $ kubectl  cluster-info\nKubernetes master is running at https://192.168.0.120:6443\nCoreDNS is running at https://192.168.0.120:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\nMetrics-server is running at https://192.168.0.120:6443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n```\n\nAnd the cluster is up and running!\n\nIf this is your only cluster, copy the config file to **~/.kube/config** for convenience. You won’t have to export the environment variable **KUBECONFIG** to access this cluster.\n\nAs we can see the load on our master node jumped up a bit\n\n```bash\nubuntu@rpi-master:~$ vmstat 1\nprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n 0  0      0 2218940  29752 873468    0    0    82   614  978 1593 10  9 76  6  0\n 0  0      0 2218688  29752 873496    0    0     0     0 2855 5331  2  3 95  0  0\n 0  0      0 2218688  29760 873496    0    0     0    32 2463 4605  1  2 97  0  0\n 2  0      0 2217132  29760 873496    0    0     0     0 5417 9919  5 12 83  0  0\n 0  0      0 2217964  29760 873496    0    0     0     0 3459 5780  1 20 78  0  0\n 0  0      0 2217664  29760 873496    0    0     0     0 3194 5897  3  4 94  0  0\n 0  0      0 2218924  29760 873496    0    0     0     0 4327 7566  4 13 83  0  0\n 0  0      0 2218672  29768 873496    0    0     0    24 3040 5547  2  3 95  0  0\n 1  0      0 2218672  29768 873496    0    0     0     4 2758 5124  2  3 95  0  0\n 4  0      0 2218672  29768 873496    0    0     0     0 3057 5681  2  3 95  0  0\n 0  0      0 2218704  29768 873496    0    0     0     0 3480 6466  3  3 94  0  0\n 0  0      0 2218704  29768 873496    0    0     0     0 3130 5789  2  2 95  0  0\n```\n\nBut there is still plenty of resources for our apps to use.\n\nWe can also verify if Traefik and the service load balancer (which emulates cloud load balancers) are working, by trying to connect to the IP of the cluster master through the browser or by running the following\n\n```bash\nupgrade@ZeroOne ~ $ curl http://192.168.0.120\n404 page not found\n```\n\nWe got a response, so that means the ingress is also working correctly. We just don’t have anything deployed yet, so Traefik does not serve anything.\n\n## Join the node\n\n```bash\nk3sup join --user ubuntu --sudo  --ssh-key ~/.ssh/upgnet/rpi  --server-ip 192.168.0.120  --ip 192.168.0.121\n```\n\nwait a couple of seconds and ... TADAM!\n\n```bash\nupgrade@ZeroOne ~ $ kubectl get node\nNAME           STATUS   ROLES    AGE   VERSION\nrpi-master     Ready    master   21m   v1.17.2+k3s1\nrpi-worker-1   Ready    \u003cnone\u003e   17s   v1.17.2+k3s1\nupgrade@ZeroOne ~ $ kubectl top node\nNAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%\nrpi-master     367m         9%     712Mi           18%\nrpi-worker-1   51m          1%     221Mi           5%\n```\n\nIf you SSH into the node and run\n\n```bash\nubuntu@rpi-worker-1:~$ free -m\n              total        used        free      shared  buff/cache   available\nMem:           3822         227        3222          10         372        3546\nSwap:             0           0           0\nubuntu@rpi-worker-1:~$ vmstat 1\nprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n 2  0      0 3299888  19420 361952    0    0   193   256  289  390  4  5 90  2  0\n 0  0      0 3299660  19420 361980    0    0     0     0  614 1029  1  1 98  0  0\n 1  0      0 3299660  19420 361980    0    0     0    16  578  994  1  0 99  0  0\n 1  0      0 3299628  19420 361980    0    0     0     0  544  951  0  1 99  0  0\n 1  0      0 3299628  19420 361980    0    0     0     0  346  582  0  0 100  0  0\n 0  0      0 3299504  19428 361980    0    0     0    12  597 1013  1  1 99  0  0\n 0  0      0 3299472  19428 361996    0    0     0     0  530  893  1  0 99  0  0\n 0  0      0 3299472  19428 361996    0    0     0     0  986 1721  1  1 98  0  0\n 1  0      0 3299220  19428 361996    0    0     0     0 1138 1940  1  2 97  0  0\n 1  0      0 3299220  19428 361996    0    0     0     0  718 1249  0  1 99  0  0\n 1  0      0 3298968  19428 361996    0    0     0     0  507  844  0  1 99  0  0\n```\n\nyou will see that the performance hit is mostly on the master. The worker node still has almost all resources available — which is also reflected by the output of the **kubectl top node** command.\n\n## It wasn’t that bad, was it?\n\nCool! So now we have our Kubernetes cluster with Traefik as Ingress controller, metrics service and a local storage provisioner. And the whole preparation took way longer than the cluster setup itself. Now it’s time to explore Kubernetes with all its glory!\n\n## And for all you UI lovers\n\nIf you like UI, especially the console ones, I strongly recommend using K9s that you can find [here](https://github.com/derailed/k9s)\n\nHere is the state of the cluster shown in K9s\n\n![list-of-pods-in-the-K9s-UI](/blog-images/list-of-pods-in-the-K9s-UI.png)\n\n![list-of-nodes-in-the-K9s-UI](/blog-images/list-of-nodes-in-the-K9s-UI.png)\n\n## Where do we go from here?\n\nSo now you have a complete running Kubernetes cluster, with one or two nodes. Traefik ingress controller is set up so you can deploy any application and use its built-in option to obtain SSL certificates to run it securely even from home. The metrics service is there, so initial monitoring of your applications is enabled and you can learn a lot about their behavior in the cluster. You can also start learning Kubernetes and training for the CKAD and CKA certification if you fancy, as you can practice almost everything apart from setting up a cluster on this cluster ;) As for me, I’m planning to deploy [IceCI](https://iceci.io/) to the cluster and start building more applications for the ARM architecture.\n\nReadout:\n\nTraefik: [https://docs.traefik.io/](https://docs.traefik.io/)\n\nK3s: [https://k3s.io/](https://k3s.io/)\n\nK3sup: [https://github.com/alexellis/k3sup](https://github.com/alexellis/k3sup)\n\nK9s: [https://github.com/derailed/k9s](https://github.com/derailed/k9s)\n\nKubernetes documentation: [https://kubernetes.io/docs/setup/](https://kubernetes.io/docs/setup/)\n"},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"building-a-kubernetes-cluster-on-raspberry-pi-running-ubuntu-server"},"buildId":"BrQC3HtKOO_MNx4RlokCY","assetPrefix":"https://icetekio.github.io","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body><script defer="" src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script><script defer="" src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script defer="" src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script></html></body></html>