{"pageProps":{"data":{"author":"Jakub Czapli≈Ñski","authorPhoto":"jakub-czaplinski.jpeg","date":"2020-05-14T07:50:39Z","image":"jetson-header-img.jpeg","slug":"how-to-connect-jetson-nano-to-kubernetes-using-k3s-and-k3sup","summary":"In this article I will show how to connect a Jetson Nano Developer board to the Kubernetes cluster to act as a GPU node.","title":"How To Connect Jetson Nano To Kubernetes Using K3s And K3sup"},"slug":"how-to-connect-jetson-nano-to-kubernetes-using-k3s-and-k3sup","content":"\nIn this article, I will show how to connect a Jetson Nano Developer board to the Kubernetes cluster to act as a GPU node. I will cover the setup of NVIDIA docker needed to run containers using GPU and connecting Jetson to the Kubernetes cluster. After successfully connecting the node to the cluster I will also show how to run a simple TensorFlow 2 training session using the GPU on the Jetson Nano.\n\nIf you are interested in setting up a K3s cluster, you can follow my other tutorial explaining how to build a K3s cluster on Raspberry Pi using Ubuntu Server 18.04. Most of the information provided here is not unique to Raspberry Pi.\n\n<link do building Kubernetes cluster..>\n\n## K3s or Kubernetes?\n\nK3s is a lightweight version of Kubernetes that is optimized for smaller installations which, in my opinion, is ideal for single board computers as it takes significantly less resources. You can read more about it here [https://k3s.io/](https://k3s.io/). K3sup, on the other hand, is a great open-source tool built by Alex Ellis for simplifying the installation of K3s clusters. You can find more information about it on the GitHub repo [https://github.com/alexellis/k3sup](https://github.com/alexellis/k3sup)\n\n## What do we need?\n\n- A K3s cluster - only a properly configured master node is required\n- NVIDIA Jetson Nano Developer board with the Developer Kit installed. For more information how to install the developer kit on the board follow the instruction in the documentation found here [https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#write](https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#write)\n- K3sup\n- 15 minutes\n\n## Plan\n\n- Setup NVIDIA docker\n- Add Jetson Nano to the K3s cluster\n- Run a simple MNIST example to showcase the usage of GPU inside Kubernetes pod\n\n## Setting up NVIDIA docker\n\nBefore we will configure Docker to use nvidia-docker as a default runtime, I would like to spend a moment on explaining why this is needed. By default, when user will run containers on Jetson Nano they will run in a same way as on any other hardware and you can't access the GPU from the container, or at least not without some hacking. If you want to test it out by yourself you can run the following command and should see similar results\n\n```bash\nroot@jetson:~# echo \"python3 -c 'import tensorflow'\" | docker run -i icetekio/jetson-nano-tensorflow /bin/bash\n2020-05-14 00:10:23.370761: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.2'; dlerror: libcudart.so.10.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/targets/aarch64-linux/lib:\n2020-05-14 00:10:23.370859: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2020-05-14 00:10:25.946896: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/targets/aarch64-linux/lib:\n2020-05-14 00:10:25.947219: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/targets/aarch64-linux/lib:\n2020-05-14 00:10:25.947273: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n```\n\nIf you now try to run the same command but adding `--runtime=nvidia` parameter to the docker command you should see something like this\n\n```bash\nroot@jetson:~# echo \"python3 -c 'import tensorflow'\" | docker run --runtime=nvidia -i icetekio/jetson-nano-tensorflow /bin/bash\n2020-05-14 00:12:16.767624: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n2020-05-14 00:12:19.386354: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libnvinfer.so.7\n2020-05-14 00:12:19.388700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libnvinfer_plugin.so.7\n/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n```\n\nThe nvidia-docker is configured, however not enabled by default. To enable docker to run nvidia-docker runtime as a default - add the `\"default-runtime\": \"nvidia\"` to the `/etc/docker/daemon.json` config file so it will look like this\n\n```jsx\n{\n    \"runtimes\": {\n        \"nvidia\": {\n            \"path\": \"nvidia-container-runtime\",\n            \"runtimeArgs\": []\n        }\n    },\n    \"default-runtime\": \"nvidia\"\n}\n```\n\nNow you can skip the `--runtime=nvidia` argument in the docker run command, and the GPU will be initialized by default. This is needed so that K3s will use Docker with the nvidia-docker runtime to allow the pods to use GPU without any hassle and special configuration.\n\n## Connecting Jetson as a Kubernetes node\n\nConnecting Jetson as a Kubernetes node using K3sup is only 1 command, however for it to work we need to be able to connect to both Jetson and the master node without a password and do `sudo` without a password, or to connect as the root user.\n\nIf you need to generate SSH keys and copy them over you can run something like this\n\n```bash\nssh-keygen -t rsa -b 4096 -f ~/.ssh/rpi -P \"\"\nssh-copy-id -i .ssh/rpi user@host\n```\n\nBy default, Ubuntu installations require users to put in password for `sudo` command. Because of that, the easier way is to user K3sup with root account. To make this work copy your `~/.ssh/authorized_keys` to `/root/.ssh` directory.\n\nBefore connecting Jetson, lets look at the cluster we want to connect it to\n\n```bash\nupgrade@ZeroOne:~$ kubectl get node -o wide\nNAME      STATUS   ROLES    AGE   VERSION        INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME\nnexus     Ready    master   32d   v1.17.2+k3s1   192.168.0.12   <none>        Ubuntu 18.04.4 LTS   4.15.0-96-generic   containerd://1.3.3-k3s1\nrpi3-32   Ready    <none>   32d   v1.17.2+k3s1   192.168.0.30   <none>        Ubuntu 18.04.4 LTS   5.3.0-1022-raspi2   containerd://1.3.3-k3s1\nrpi3-64   Ready    <none>   32d   v1.17.2+k3s1   192.168.0.32   <none>        Ubuntu 18.04.4 LTS   5.3.0-1022-raspi2   containerd://1.3.3-k3s1\n```\n\nAs you may notice, master node is a `nexus` host on IP `192.168.0.12` that is running containerd. By default, k3s is running containerd but that can be modified. The containerd is a bit problematic as we did set up the nvidia-docker to run with Docker and it is needed for the GPU. Fortunately, to switch from containerd to Docker we just need to pass one additional parameter to the k3sup command. So, finally, to connect our Jetson to the cluster we can run:\n\n```bash\nk3sup join --ssh-key ~/.ssh/rpi  --server-ip 192.168.0.12  --ip 192.168.0.40   --k3s-extra-args '--docker'\n```\n\nThe IP `192.168.0.40` is my Jetson Nano. As you can see we passed the `--k3s-extra-args '--docker'` flag that passes the `--docker` flag to k3s agent while installing it. Thanks to that, we are using the docker with nvidia-docker setup rather than containerd.\n\nTo check if the node connected correctly we can run `kubectl get node -o wide`\n\n```bash\nupgrade@ZeroOne:~$ kubectl get node -o wide\nNAME      STATUS   ROLES    AGE   VERSION        INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME\nnexus     Ready    master   32d   v1.17.2+k3s1   192.168.0.12   <none>        Ubuntu 18.04.4 LTS   4.15.0-96-generic   containerd://1.3.3-k3s1\nrpi3-32   Ready    <none>   32d   v1.17.2+k3s1   192.168.0.30   <none>        Ubuntu 18.04.4 LTS   5.3.0-1022-raspi2   containerd://1.3.3-k3s1\nrpi3-64   Ready    <none>   32d   v1.17.2+k3s1   192.168.0.32   <none>        Ubuntu 18.04.4 LTS   5.3.0-1022-raspi2   containerd://1.3.3-k3s1\njetson    Ready    <none>   11s   v1.17.2+k3s1   192.168.0.40   <none>        Ubuntu 18.04.4 LTS   4.9.140-tegra       docker://19.3.6\n```\n\n## Simple validation\n\nWe can now run the pod using the same docker image and command to check if we will have the same results as running docker on Jetson Nano at the beginning of this article.\n\nTo do this, we can apply this pod spec:\n\n```bash\napiVersion: v1\nkind: Pod\nmetadata:\n  name: gpu-test\nspec:\n  nodeSelector:\n    kubernetes.io/hostname: jetson\n  containers:\n  - image: icetekio/jetson-nano-tensorflow\n    name: gpu-test\n    command:\n    - \"/bin/bash\"\n    - \"-c\"\n    - \"echo 'import tensorflow' | python3\"\n  restartPolicy: Never\n```\n\nWait for the docker image to pull and then view the logs by running:\n\n```bash\nupgrade@ZeroOne:~$ kubectl logs gpu-test\n2020-05-14 10:01:51.341661: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n2020-05-14 10:01:53.996300: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libnvinfer.so.7\n2020-05-14 10:01:53.998563: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libnvinfer_plugin.so.7\n/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n```\n\nAs you can see, we have similar log messages as previously running docker on the Jetson!\n\n## Running MNIST training\n\nWe have a running node with GPU support, so now we can test out the \"Hello world\" of Machine Learning and run the TensorFlow 2 model example using MNIST dataset.\n\nTo run a simple training session that will prove the usage of GPU apply the manifest below.\n\n```bash\napiVersion: v1\nkind: Pod\nmetadata:\n  name: mnist-training\nspec:\n  nodeSelector:\n    kubernetes.io/hostname: jetson\n  initContainers:\n    - name: git-clone\n      image: iceci/utils\n      command:\n        - \"git\"\n        - \"clone\"\n        - \"https://github.com/IceCI/example-mnist-training.git\"\n        - \"/workspace\"\n      volumeMounts:\n        - mountPath: /workspace\n          name: workspace\n  containers:\n    - image: icetekio/jetson-nano-tensorflow\n      name: mnist\n      command:\n        - \"python3\"\n        - \"/workspace/mnist.py\"\n      volumeMounts:\n        - mountPath: /workspace\n          name: workspace\n  restartPolicy: Never\n  volumes:\n    - name: workspace\n      emptyDir: {}\n```\n\nAs you can see in the log below, the GPU is running.\n\n```bash\n...\n2020-05-14 11:30:02.846289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n2020-05-14 11:30:02.846434: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n....\n```\n\nIf you are on the node, you can test the usage of CPU and GPU by running `tegrastats` command\n\n```bash\nupgrade@jetson:~$ tegrastats --interval 5000\nRAM 2462/3964MB (lfb 2x4MB) SWAP 362/1982MB (cached 6MB) CPU [52%@1479,41%@1479,43%@1479,34%@1479] EMC_FREQ 0% GR3D_FREQ 9% PLL@23.5C CPU@26C PMIC@100C GPU@24C AO@28.5C thermal@25C POM_5V_IN 3410/3410 POM_5V_GPU 451/451 POM_5V_CPU 1355/1355\nRAM 2462/3964MB (lfb 2x4MB) SWAP 362/1982MB (cached 6MB) CPU [53%@1479,42%@1479,45%@1479,35%@1479] EMC_FREQ 0% GR3D_FREQ 9% PLL@23.5C CPU@26C PMIC@100C GPU@24C AO@28.5C thermal@24.75C POM_5V_IN 3410/3410 POM_5V_GPU 451/451 POM_5V_CPU 1353/1354\nRAM 2461/3964MB (lfb 2x4MB) SWAP 362/1982MB (cached 6MB) CPU [52%@1479,38%@1479,43%@1479,33%@1479] EMC_FREQ 0% GR3D_FREQ 10% PLL@24C CPU@26C PMIC@100C GPU@24C AO@29C thermal@25.25C POM_5V_IN 3410/3410 POM_5V_GPU 493/465 POM_5V_CPU 1314/1340\n```\n\n## Summary\n\nAs you can see, hooking up a Jetson Nano to a Kubernetes cluster is a pretty simple and straightforward process. In just a couple of minutes, you'll be able to leverage Kubernetes to run machine learning workloads - using the power of NVIDIA's pocket-sized GPU as well. You'll be able to run any GPU containers designed for Jetson Nano on Kubernetes, which can simplify your development and testing.\n\n## Readout\n\n- Jetson Nano Developer Kit documentation: [https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#intro](https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#intro)\n- NVIDIA docker repository including the overview of NVIDIA docker: [https://github.com/NVIDIA/nvidia-docker](https://github.com/NVIDIA/nvidia-docker)\n- K3s website: [https://k3s.io/](https://k3s.io/)\n- K3sup: [https://github.com/alexellis/k3sup](https://github.com/alexellis/k3sup)\n- MNIST model code used from TensorFlow 2 documentation: [https://www.tensorflow.org/overview](https://www.tensorflow.org/overview)\n"},"__N_SSG":true}